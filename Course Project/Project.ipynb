{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''Classification model - Logistic Regression'''\n",
    "\n",
    "'''Import all necessary library files'''\n",
    "\n",
    "from collections import Counter\n",
    "import glob\n",
    "import hashlib\n",
    "import io\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import re\n",
    "import string\n",
    "from sklearn.cross_validation import KFold\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from nltk.classify.scikitlearn import SklearnClassifier\n",
    "import pandas as pd\n",
    "%matplotlib inline\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "import metacritic\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>﻿Review</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>That such intelligence could be contained in a...</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Shines with a kind of inspired madness.</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Here is the most passionate and tender love st...</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>One of the greatest of all American films, but...</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A remarkable film.</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             ﻿Review  Sentiment\n",
       "0  That such intelligence could be contained in a...        100\n",
       "1            Shines with a kind of inspired madness.        100\n",
       "2  Here is the most passionate and tender love st...        100\n",
       "3  One of the greatest of all American films, but...        100\n",
       "4                                 A remarkable film.        100"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''Place the reviews.txt file in the working directory and then run all the modules below'''\n",
    "df = pd.read_csv(\"reviews.txt\",sep='\\t')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>﻿Review</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>44004</th>\n",
       "      <td>The lack of imagination in Stargate is distres...</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44005</th>\n",
       "      <td>Oz the Great and Powerful is an oppressive, bl...</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44006</th>\n",
       "      <td>It is a grand-looking, grandly empty pageant.</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44007</th>\n",
       "      <td>There’s exactly one good scene in all of The H...</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44008</th>\n",
       "      <td>Man on a Ledge just made me think of an old Va...</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 ﻿Review  Sentiment\n",
       "44004  The lack of imagination in Stargate is distres...         25\n",
       "44005  Oz the Great and Powerful is an oppressive, bl...         25\n",
       "44006      It is a grand-looking, grandly empty pageant.         25\n",
       "44007  There’s exactly one good scene in all of The H...         25\n",
       "44008  Man on a Ledge just made me think of an old Va...         25"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Data split into positive and negative:**\n",
    "\n",
    "We split our dataset by considering the reviews with scores above 65 to be Positive and those ones that are below 65 to be considered as negative and store them into two separate dataframes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>21027.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>81.959623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>9.922689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>67.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>75.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>80.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>90.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Sentiment\n",
       "count  21027.000000\n",
       "mean      81.959623\n",
       "std        9.922689\n",
       "min       67.000000\n",
       "25%       75.000000\n",
       "50%       80.000000\n",
       "75%       90.000000\n",
       "max      100.000000"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#split positive and negative reviews based on scores \n",
    "pos = df[df.Sentiment > 65]\n",
    "neg = df[df.Sentiment < 65]\n",
    "pos.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>22843.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>44.681434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>15.531329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>38.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>50.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>60.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>63.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Sentiment\n",
       "count  22843.000000\n",
       "mean      44.681434\n",
       "std       15.531329\n",
       "min        0.000000\n",
       "25%       38.000000\n",
       "50%       50.000000\n",
       "75%       60.000000\n",
       "max       63.000000"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neg.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''Drop the Sentiment column from the dataframe'''\n",
    "pos = pos.drop('Sentiment', 1)\n",
    "neg = neg.drop('Sentiment',1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Praveen\\Desktop\\CS-579-Project\\data-LR\\train\\pos\n"
     ]
    }
   ],
   "source": [
    "'''Create a folder called data-MNB in your working directory along with pos and neg sub folders present\n",
    "in both train and test folders. After creation navigate using cd command to the pos sub-folder under train. '''\n",
    "\n",
    "cd C:\\Users\\Praveen\\Desktop\\CS-579-Project\\data-LR\\train\\pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "'''Storing each review from the positive dataframe into the positive sub-folder'''\n",
    "i=1\n",
    "for index, row in pos.iterrows():\n",
    "    if i > len(pos):\n",
    "        break\n",
    "    else:\n",
    "        f = open(str(i)+'.txt', 'w')\n",
    "        f.write(row[0])\n",
    "        f.close()\n",
    "        i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Praveen\\Desktop\\CS-579-Project\\data-LR\\train\\neg\n"
     ]
    }
   ],
   "source": [
    "'''Navigate using cd command to the neg sub-folder under train'''\n",
    "cd C:\\Users\\Praveen\\Desktop\\CS-579-Project\\data-LR\\train\\neg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''Storing each review from the negative dataframe into the negative sub-folder'''\n",
    "i=1\n",
    "for index, row in neg.iterrows():\n",
    "    if i > len(neg):\n",
    "        break\n",
    "    else:\n",
    "        f = open(str(i)+'.txt', 'w')\n",
    "        f.write(row[0])\n",
    "        f.close()\n",
    "        i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Praveen\\Desktop\\CS-579-Project\n"
     ]
    }
   ],
   "source": [
    "'''Back up again to your working directory using triple cd '''\n",
    "cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "subdirectories are:['test', 'train']\n"
     ]
    }
   ],
   "source": [
    "'''Setting path and listing out the sub-directories in the specified path'''\n",
    "path = 'data-LR'\n",
    "print('subdirectories are:' + str(os.listdir(path)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_files(path):\n",
    "    \"\"\" Return a list of file names in this directory that end in .txt \n",
    "    The list should be sorted alphabetically by file name.\n",
    "    Params:\n",
    "        path....a directory containing .txt review files.\n",
    "    Returns:\n",
    "        a list of .txt file names, sorted alphabetically.\n",
    "    \"\"\"\n",
    "    files = os.listdir(path)\n",
    "    res=[]\n",
    "    for f in files:\n",
    "        if f.endswith('.txt'):\n",
    "                res.append((path + os.sep + f))\n",
    "    return sorted(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21027\n",
      "22843\n"
     ]
    }
   ],
   "source": [
    "'''Print the length of positive and negative files before splitting test data'''\n",
    "pos_train = get_files(path + os.sep + 'train' + os.sep + 'pos')\n",
    "neg_train = get_files(path + os.sep + 'train' + os.sep + 'neg')\n",
    "all_train = pos_train + neg_train\n",
    "print len(pos_train)\n",
    "print len(neg_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''Split testing data from the whole dataset'''\n",
    "for i in range(18001,len(pos_train)+1): \n",
    "    shutil.move(\"data-LR/train/pos/\" + str(i)+'.txt', \"data-LR/test/pos/\" + str(i)+'.txt')\n",
    "for i in range(18001,len(neg_train)+1):\n",
    "    shutil.move(\"data-LR/train/neg/\" + str(i)+'.txt', \"data-LR/test/neg/\" + str(i)+'.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18000\n",
      "18000\n"
     ]
    }
   ],
   "source": [
    "'''Print the length of positive and negative training files after splitting test data'''\n",
    "pos_train_files = get_files(path + os.sep + 'train' + os.sep + 'pos')\n",
    "neg_train_files = get_files(path + os.sep + 'train' + os.sep + 'neg')\n",
    "all_train_files = pos_train_files + neg_train_files\n",
    "print len(pos_train_files)\n",
    "print len(neg_train_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found 18000 positive and 18000 negative training files\n",
      "first positive file: data-LR\\train\\pos\\1.txt\n",
      "first negative file: data-LR\\train\\neg\\1.txt\n"
     ]
    }
   ],
   "source": [
    "print('found %d positive and %d negative training files' %\n",
    "      (len(pos_train_files), len(neg_train_files)))\n",
    "print('first positive file: %s' % pos_train_files[0])\n",
    "print('first negative file: %s' % neg_train_files[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_true_labels(file_names):\n",
    "    \"\"\"Return a *numpy array* of ints for the true sentiment labels of each file.\n",
    "    1 means positive, 0 means negative. Use the name of the file to determine\n",
    "    the true label.\n",
    "    Params:\n",
    "        file_names....a list of .txt file paths, e.g., data/train/pos/10057_9.txt\n",
    "    Returns:\n",
    "        a numpy array of 1 or 0 values corresponding to each element\n",
    "        of file_names, where 1 indicates a positive review, and 0\n",
    "        indicates a negative review.\n",
    "    \"\"\"\n",
    "    x=np.ones((len(file_names[:(len(file_names)/2)]),), dtype=np.int)\n",
    "    y=np.zeros((len(file_names[(len(file_names)/2):]),), dtype=np.int)\n",
    "    z=np.concatenate([x, y])\n",
    "    return z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "first 3 and last 3 labels are: [1 1 1 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "labels = get_true_labels(all_train_files)\n",
    "print('first 3 and last 3 labels are: %s' % str(labels[[1,2,3,-3,-2,-1]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u\"Coppola brilliantly conjures the young queen's insular world, in which she was both isolated and claustrophobically scrutinized.\""
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def file2string(filename):\n",
    "    return io.open(filename,encoding='utf8').readlines()[0]\n",
    "   \n",
    "file2string(pos_train_files[10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def tokenize(text):\n",
    "    \"\"\"Given a string, return a list of tokens such that: (1) all\n",
    "    tokens are lowercase, (2) all punctuation is removed. Note that\n",
    "    underscore (_) is not considered punctuation.\n",
    "    Params:\n",
    "        text....a string\n",
    "    Returns:\n",
    "        a list of tokens\n",
    "    \"\"\"\n",
    "    x=re.findall(r'\\w+',text.lower())\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "matrix represents 36000 documents with 37810 features\n",
      "first doc has terms:\n",
      "[398, 1485, 2932, 6992, 7317, 10948, 13300, 16539, 17144, 17504, 18345, 21311, 21890, 23100, 30245, 30854, 30981, 32375, 33485]\n"
     ]
    }
   ],
   "source": [
    "def do_vectorize(filenames, tokenizer_fn=tokenize, min_df=1,\n",
    "                 max_df=1., binary=True, ngram_range=(1,1)):\n",
    "    \"\"\"\n",
    "    Convert a list of filenames into a sparse csr_matrix, where\n",
    "    each row is a file and each column represents a unique word.\n",
    "    Use sklearn's CountVectorizer: http://goo.gl/eJ2PJ5\n",
    "    Params:\n",
    "        filenames.......list of review file names\n",
    "        tokenizer_fn....the function used to tokenize each document\n",
    "        min_df..........remove terms from the vocabulary that don't appear\n",
    "                        in at least this many documents\n",
    "        max_df..........remove terms from the vocabulary that appear in more\n",
    "                        than this fraction of documents\n",
    "        binary..........If true, each documents is represented by a binary\n",
    "                        vector, where 1 means a term occurs at least once in \n",
    "                        the document. If false, the term frequency is used instead.\n",
    "        ngram_range.....A tuple (n,m) means to use phrases of length n to m inclusive.\n",
    "                        E.g., (1,2) means consider unigrams and bigrams.\n",
    "    Return:\n",
    "        A tuple (X, vec), where X is the csr_matrix of feature vectors,\n",
    "        and vec is the CountVectorizer object.\n",
    "    \"\"\"\n",
    "    vectorizer = CountVectorizer(input='filename',tokenizer=tokenizer_fn,min_df=min_df,\n",
    "                 max_df=max_df, binary=binary, ngram_range=ngram_range,dtype=int)\n",
    "    dtm = vectorizer.fit_transform(filenames)\n",
    "    \n",
    "    return (dtm,vectorizer)\n",
    "    \n",
    "matrix,vec = do_vectorize(all_train_files)\n",
    "\n",
    "print ('matrix represents %d documents with %d features' % (matrix.shape[0], matrix.shape[1]))\n",
    "print('first doc has terms:\\n%s' % (str(sorted(matrix[0].nonzero()[1]))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "first shuffled document data-LR\\train\\pos\\10103.txt has label 1 and terms: [1442, 1697, 1911, 2049, 2651, 2932, 3106, 5917, 9820, 10213, 10502, 10577, 12545, 12805, 15577, 15968, 17565, 19152, 19277, 21918, 22362, 22628, 29313, 29580, 30008, 30854, 33901]\n"
     ]
    }
   ],
   "source": [
    "# Do not modify. This is to randomize the order of the documents, but\n",
    "# in a way that is consistent across platforms.\n",
    "# You should run this block once to get the shuffled data.\n",
    "def repeatable_random(seed):\n",
    "    hash = str(seed)\n",
    "    while True:\n",
    "        hash = hashlib.md5(hash).digest()\n",
    "        for c in hash:\n",
    "            yield ord(c)\n",
    "\n",
    "def repeatable_shuffle(X, y, filenames):\n",
    "    r = repeatable_random(42) \n",
    "    indices = sorted(range(X.shape[0]), key=lambda x: next(r))\n",
    "    return X[indices], y[indices], np.array(filenames)[indices]\n",
    "\n",
    "X, y, filenames = repeatable_shuffle(matrix, labels, all_train_files)\n",
    "\n",
    "print('first shuffled document %s has label %d and terms: %s' % \n",
    "      (filenames[0], y[0], sorted(X[0].nonzero()[1])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Logistic Regression**\n",
    "\n",
    "Logistic regression fits a logistic model to data and makes predictions about the probability of an event (between 0 and 1) in our case its going to be either positive or negative. It is a linear model for classification rather than regression. It is also known as logit regression, maximum-entropy classification (MaxEnt) or the log-linear classifier. The goal of this model is to learn from the training data so that you can predict the label of new examples that we haven't seen before and don't know the label of."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Do not modify. This creates a LogsticRegression object, which\n",
    "# you will use in the do_cross_validation method below.\n",
    "def get_clf():\n",
    "    return LogisticRegression(random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 0 accuracy=0.7400\n",
      "fold 1 accuracy=0.7409\n",
      "fold 2 accuracy=0.7584\n",
      "fold 3 accuracy=0.7391\n",
      "fold 4 accuracy=0.7418\n",
      "fold 5 accuracy=0.7436\n",
      "fold 6 accuracy=0.7453\n",
      "fold 7 accuracy=0.7416\n",
      "average cross validation accuracy using logistic regression classifier=0.7438\n"
     ]
    }
   ],
   "source": [
    "#Logistic Regression\n",
    "def do_cross_validation_LR(X, y, n_folds=8, verbose=False):\n",
    "    \"\"\"\n",
    "    Perform n-fold cross validation, calling get_clf() to train n\n",
    "    different classifiers. Use sklearn's KFold class: http://goo.gl/wmyFhi\n",
    "    Be sure not to shuffle the data, otherwise your output will differ.\n",
    "    Params:\n",
    "        X.........a csr_matrix of feature vectors\n",
    "        y.........the true labels of each document\n",
    "        n_folds...the number of folds of cross-validation to do\n",
    "        verbose...If true, report the testing accuracy for each fold.\n",
    "    Return:\n",
    "        the average testing accuracy across all folds.\n",
    "    \"\"\"\n",
    "    cv = KFold(len(y), n_folds)\n",
    "    acc = []\n",
    "    n=0\n",
    "    for train_idx, test_idx in cv:\n",
    "        clf = get_clf()\n",
    "        clf.fit(X[train_idx], y[train_idx])\n",
    "        predicted = clf.predict(X[test_idx])\n",
    "        accuracy = accuracy_score(y[test_idx], predicted)\n",
    "        acc.append(accuracy)\n",
    "        if verbose:\n",
    "            print 'fold %d accuracy=%.4f' % (n,accuracy)\n",
    "        n=n+1\n",
    "    avg = np.mean(acc)\n",
    "    return avg\n",
    "    \n",
    "print('average cross validation accuracy using logistic regression classifier=%.4f' %\n",
    "      do_cross_validation_LR(X, y, verbose=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def do_expt_LR(filenames, y, tokenizer_fn=tokenize,\n",
    "            min_df=1, max_df=1., binary=True,\n",
    "            ngram_range=(1,1), n_folds=8):\n",
    "    \"\"\"\n",
    "    Run one experiment, which consists of vectorizing each file,\n",
    "    performing cross-validation, and returning the average accuracy.\n",
    "    You should call do_vectorize and do_cross_validation here.\n",
    "    Params:\n",
    "        filenames.......list of review file names\n",
    "        y...............the true sentiment labels for each file\n",
    "        tokenizer_fn....the function used to tokenize each document\n",
    "        min_df..........remove terms from the vocabulary that don't appear\n",
    "                        in at least this many documents\n",
    "        max_df..........remove terms from the vocabulary that appear in more\n",
    "                        than this fraction of documents\n",
    "        binary..........If true, each documents is represented by a binary\n",
    "                        vector, where 1 means a term occurs at least once in \n",
    "                        the document. If false, the term frequency is used instead.\n",
    "        ngram_range.....A tuple (n,m) means to use phrases of length n to m inclusive.\n",
    "                        E.g., (1,2) means consider unigrams and bigrams.\n",
    "        n_folds.........The number of cross-validation folds to use.\n",
    "    Returns:\n",
    "        the average cross validation testing accuracy.\n",
    "    \"\"\"\n",
    "    m,vec = do_vectorize(filenames,binary=binary,tokenizer_fn=tokenizer_fn,min_df=min_df,max_df=max_df)\n",
    "    res=(do_cross_validation_LR(m,y,n_folds=n_folds))\n",
    "    #avg = np.mean(res)\n",
    "\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy using Logistic regression with default settings: 0.7439\n"
     ]
    }
   ],
   "source": [
    "print('accuracy using Logistic regression with default settings: %.4g' % do_expt_LR(filenames, y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZEAAAELCAYAAAAY3LtyAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1a47bc50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[0.72994444444444451,\n",
       " 0.74252777777777779,\n",
       " 0.7454722222222222,\n",
       " 0.74533333333333329,\n",
       " 0.74552777777777768,\n",
       " 0.7446666666666667]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def compare_n_folds(filenames, y):\n",
    "    \"\"\"\n",
    "    Vary the setting of n_folds parameter in the do_expt \n",
    "    function to be in [2,5,10,15,20,25]. For each setting, call do_expt and \n",
    "    store the resulting accuracy. Plot the accuracies for each setting.\n",
    "    Also return the list of accuracies. Use the default value for all\n",
    "    other arguments to the do_expt function.\n",
    "    Params:\n",
    "        filenames....list of training file names\n",
    "        y............true labels for each file (a numpy array)\n",
    "    Returns:\n",
    "        a list of average testing accuracies, one per fold.\n",
    "    \"\"\"\n",
    "    fold=[2,5,10,15,20,25]\n",
    "    avg_acc_LR=[]\n",
    "    for f in fold:\n",
    "        avg_acc_LR.append(do_expt_LR(filenames,y,n_folds=f))\n",
    "        \n",
    "    plt.xlabel('n_folds')\n",
    "    plt.ylabel('accuracy using LR')\n",
    "    plt.plot(fold,avg_acc_LR,'bo-')\n",
    "    plt.show()\n",
    "    \n",
    "    return avg_acc_LR\n",
    "    \n",
    "compare_n_folds(filenames, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Graph inference**\n",
    "\n",
    "When number of folds increases for a fixed amount of data, number of data within each fold decreases. Hence, less data is available for testing. Also, more data is available for training purposes. Therefore, effect of increasing number of folds on accuracy becomes twofold. It trains the model more and tests the model with less data per fold. Hence, accuracy increases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.74386111111111108, 0.74344444444444435]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def compare_binary(filenames, y):\n",
    "    \"\"\"\n",
    "    How does the binary parameter affect results? \n",
    "    Call do_expt twice, once with binary=True, and once with binary=False.\n",
    "    Return the average accuracies for each. Use the default parameters for the\n",
    "    remaining arguments in do_expt.\n",
    "    Params:\n",
    "        filenames....list of training file names\n",
    "        y............true labels for each file (a numpy array)\n",
    "    Returns:\n",
    "        a list of average testing accuracies. The first entry\n",
    "        is for binary=True, the second is for binary=False.\n",
    "    \"\"\"\n",
    "    avg_LR=[]\n",
    "    avg_LR.append(do_expt_LR(filenames,y,binary=True))\n",
    "    avg_LR.append(do_expt_LR(filenames,y,binary=False))\n",
    "    return avg_LR\n",
    "\n",
    "compare_binary(filenames, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def tokenize_with_punct(text):\n",
    "    \"\"\"Given a string, return a list of tokens such that: (1) all\n",
    "    tokens are lowercase, (2) all punctuation is kept as separate tokens.\n",
    "    Note that underscore (_) is not considered punctuation.\n",
    "    Params:\n",
    "        text....a string\n",
    "    Returns:\n",
    "        a list of tokens\n",
    "    \"\"\"\n",
    "    y=re.sub(r'[\\n\\r\\x85]', ' ', text.lower())\n",
    "    x=re.findall(r\"[\\w]+|[\\S]\", y.lower())\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def tokenize_with_not(text):\n",
    "    \"\"\"Does the same thing as tokenize_with_punct, with the following difference:\n",
    "    whenever the term 'not' appears, change the two subsequent tokens to have the prefix\n",
    "    'not_' prior to the token. See the example below. You may call \n",
    "    tokenize_with_punct as a subroutine.\n",
    "    Params:\n",
    "        text....a string\n",
    "    Returns:\n",
    "        a list of tokens\n",
    "    \"\"\"\n",
    "    res= []\n",
    "    \n",
    "    k=0\n",
    "    for token in tokenize_with_punct(text):\n",
    "        if token == 'not':\n",
    "            k=2\n",
    "            res.append(token)\n",
    "        else:\n",
    "            if k>0:\n",
    "                join = 'not_' + token\n",
    "                res.append(join)\n",
    "                k = k-1\n",
    "            else:\n",
    "                res.append(token)\n",
    "\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.74386111111111108, 0.7436666666666667, 0.74622222222222223]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def tokenizer_expt(all_train_files, y):\n",
    "    \"\"\"\n",
    "    How does the tokenizer affect results? \n",
    "    Call do_expt three times, using three different tokenizers:\n",
    "    1- tokenize\n",
    "    2- tokenize_with_punct\n",
    "    3- tokenize_with_not\n",
    "    Return the average cross-validation accuracy for each approach,\n",
    "    in the above order. Use the default parameters for all other \n",
    "    arguments to do_expt.\n",
    "    Params:\n",
    "        filenames....list of training file names\n",
    "        y............true labels for each file (a numpy array)\n",
    "    Returns:\n",
    "        a list of average testing accuracies for each tokenizer.\n",
    "    \"\"\"\n",
    "    avg_LR=[]\n",
    "    avg_LR.append(do_expt_LR(all_train_files,y,tokenizer_fn=tokenize))\n",
    "    avg_LR.append(do_expt_LR(all_train_files,y,tokenizer_fn=tokenize_with_punct))\n",
    "    avg_LR.append(do_expt_LR(all_train_files,y,tokenizer_fn=tokenize_with_not))\n",
    "    return avg_LR\n",
    "\n",
    "tokenizer_expt(filenames, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZEAAAEQCAYAAABxzUkqAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1818cda0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[0.74622222222222223,\n",
       " 0.74519444444444449,\n",
       " 0.74408333333333332,\n",
       " 0.74391666666666667,\n",
       " 0.74302777777777784,\n",
       " 0.74199999999999999,\n",
       " 0.74086111111111108,\n",
       " 0.74169444444444443,\n",
       " 0.7412777777777777,\n",
       " 0.74086111111111108]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def min_df_expt(filenames, y):\n",
    "    \"\"\"\n",
    "    Vary the setting of min_df parameter in the do_expt \n",
    "    function to be ints in the range (1,10) (inclusive). For each setting,\n",
    "    call do_expt and store the resulting accuracy. Plot the accuracies for each setting.\n",
    "    Also return the list of accuracies. Use the default value for all\n",
    "    other arguments to the do_expt function, except that the tokenizer\n",
    "    should be tokenize_with_not.\n",
    "    Params:\n",
    "        filenames....list of training file names\n",
    "        y............true labels for each file (a numpy array)\n",
    "    Returns:\n",
    "        a list of average testing accuracies, one per min_df value.\n",
    "    \"\"\"\n",
    "    avg_LR=[]\n",
    "    for i in range(1,11):\n",
    "        avg_LR.append(do_expt_LR(filenames,y,tokenizer_fn=tokenize_with_not,min_df=i,max_df=1., binary=True, ngram_range=(1,1)))\n",
    "    #plt.plot(avg,color='b')\n",
    "    plt.xlabel('min_df')\n",
    "    plt.ylabel('accuracy using LR')\n",
    "    plt.plot(range(1,11),avg_LR,'bo-')\n",
    "    plt.show()\n",
    "    return avg_LR\n",
    "\n",
    "min_df_expt(filenames, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Decline in accuracy**\n",
    "\n",
    "The min_df parameter refers particularly to the cut-off value for ignoring terms that have lower document frequency than the mentioned value. Setting a too low value will ignore very rare terms which doesn't count towards sentiment calculation. A bit higher value will ignore sufficient rare terms which will improve accuracy. If the value is high, the model will ignore necessary terms as well and that's why we observe a decline in accuracy in the right hand side of the above graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZkAAAEQCAYAAABiGgneAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1b0853c8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[0.74316666666666675,\n",
       " 0.74358333333333326,\n",
       " 0.74377777777777776,\n",
       " 0.74438888888888888,\n",
       " 0.74411111111111106,\n",
       " 0.74441666666666662,\n",
       " 0.74424999999999997,\n",
       " 0.74536111111111114,\n",
       " 0.74536111111111114,\n",
       " 0.74519444444444449]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def max_df_expt(filenames, y):\n",
    "    \"\"\"\n",
    "    Vary the setting of max_df parameter in the do_expt \n",
    "    function to be one of [.1, .2, .3, .4, .5, .6, .7, .8, .9, 1.].\n",
    "    For each setting, call do_expt and store the resulting accuracy.\n",
    "    Plot the accuracies for each setting. Also return the list of accuracies.\n",
    "    Use the default value for all other arguments to the do_expt function,\n",
    "    except that the tokenizer=tokenize_with_not and min_df=2.\n",
    "    Params:\n",
    "        filenames....list of training file names\n",
    "        y............true labels for each file (a numpy array)\n",
    "    Returns:\n",
    "        a list of average testing accuracies, one per max_df value.\n",
    "    \"\"\"\n",
    "    avg_LR=[]\n",
    "    max = [.1, .2, .3, .4, .5, .6, .7, .8, .9, 1.]\n",
    "    for i in max:\n",
    "        avg_LR.append(do_expt_LR(filenames,y,tokenizer_fn=tokenize_with_not,min_df=2,max_df=i, binary=True, ngram_range=(1,1)))\n",
    "    \n",
    "    plt.xlabel('max_df')\n",
    "    plt.ylabel('accuracy using LR')\n",
    "    plt.plot(max,avg_LR,'bo-')\n",
    "    plt.show()\n",
    "    return avg_LR\n",
    "    \n",
    "max_df_expt(filenames, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression classifier accuracy for training data: 0.938\n",
      "Logistic Regression classifier accuracy for test data: 0.74\n"
     ]
    }
   ],
   "source": [
    "X, vec = do_vectorize(filenames, tokenizer_fn=tokenize_with_not,\n",
    "                      binary=True, min_df=2, max_df=.7)\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n",
    "clf = get_clf()\n",
    "clf.fit(X_train, Y_train)\n",
    "print 'Logistic Regression classifier accuracy for training data:', round(clf.score(X_train, Y_train), 3)\n",
    "print 'Logistic Regression classifier accuracy for test data:', round(clf.score(X_test, Y_test),3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<type 'numpy.ndarray'>\n",
      "(1L, 24221L)\n"
     ]
    }
   ],
   "source": [
    "#clf = get_clf()\n",
    "print type(clf.coef_)\n",
    "print clf.coef_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.1601789  -0.3742802  -0.04094723 -0.01446321 -0.25829122 -0.148396\n",
      " -0.1525353   0.35590702 -0.25288177 -0.13078207]\n",
      "[u'!', u'\"', u'#', u'$', u'%', u'&', u\"'\", u'(', u')', u'*']\n"
     ]
    }
   ],
   "source": [
    "# Here are the first 10 coefficients.\n",
    "print (clf.coef_[0][:10])\n",
    "\n",
    "# The features corresponding to them can be found using the vectorizer's get_feature_names method.\n",
    "print(vec.get_feature_names()[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top positive coefs: [(u'exhilarating', 1.8806495874506894), (u'observant', 1.7936650345103218), (u'dazzling', 1.7402614379596228), (u'remarkable', 1.7026976851513291), (u'hilarious', 1.6942880452427078)]\n",
      "top negative coefs: [(u'worst', -2.1926024982375738), (u'dull', -2.0974927865955979), (u'pointless', -2.0165020483092362), (u'unfunny', -1.9745497771120379), (u'muddled', -1.9485014548289517)]\n"
     ]
    }
   ],
   "source": [
    "#Using the Logistic regression classifier\n",
    "def get_top_coefficients(clf, vec, n=10):\n",
    "    \"\"\" Get the top n coefficients for each class (positive/negative).\n",
    "    Params:\n",
    "        clf...a LogisticRegression object that has already been fit to data.\n",
    "        vec...a CountVectorizer\n",
    "        n.....the number of features to print per class.\n",
    "    Returns:\n",
    "        Two lists of tuples. The first list containts the top terms for the positive\n",
    "        class. Each entry is a tuple of (string, float) pairs, where\n",
    "        string is the feature name and float is the coefficient.\n",
    "        The second list is the same but for the negative class.\n",
    "        In each list, entries should be sorted in descending order of \n",
    "        absolute value.\"\"\"\n",
    "    pos=[]\n",
    "    neg=[]\n",
    "    for k,v in enumerate(vec.get_feature_names()):\n",
    "        if clf.coef_[0][k] > 0.:\n",
    "            pos.append((v,clf.coef_[0][k]))\n",
    "        else:\n",
    "            neg.append((v,clf.coef_[0][k]))\n",
    "            \n",
    "    positive = sorted(pos,key=lambda x: x[1],reverse=True)\n",
    "    p1=positive[:n]\n",
    "    negative = sorted(neg,key=lambda x: x[1])\n",
    "    n1=negative[:n]\n",
    "    return (p1,n1)\n",
    "\n",
    "pos_coef, neg_coef = get_top_coefficients(clf, vec, n=5)\n",
    "print('top positive coefs: %s' % str(pos_coef))\n",
    "print('top negative coefs: %s' % str(neg_coef))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13769"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Do not modify.\n",
    "def index_of_term(vec, term):\n",
    "    \"\"\" This returns the column index corresponding to this term.\"\"\"\n",
    "    return vec.get_feature_names().index(term)\n",
    "\n",
    "index_of_term(vec, 'movie')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "features = vec.get_feature_names()\n",
    "eyematrix = np.eye(len(features))\n",
    "# compute per-word probability by running I-matrix through our classifier\n",
    "perword_proba = clf.predict_proba(eyematrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 positive Predictor Words according to Logistic Regression classifier: \n",
      "                word  prob negative\n",
      "14980      observant       0.178454\n",
      "5222        dazzling       0.186419\n",
      "17739     remarkable       0.192183\n",
      "9862       hilarious       0.193492\n",
      "22629  unforgettable       0.197206\n",
      "6483        dynamite       0.203187\n",
      "2744     brilliantly       0.206703\n",
      "12925      masterful       0.206972\n",
      "12930    masterpiece       0.210218 \n",
      "\n",
      "Top 10 negative Predictor Words according to Logistic Regression classifier: \n",
      "               word  prob positive\n",
      "6405           dull       0.085936\n",
      "16331     pointless       0.092514\n",
      "22642       unfunny       0.096097\n",
      "13795       muddled       0.098384\n",
      "22796  unsatisfying       0.103929\n",
      "23846       witless       0.109129\n",
      "7561          fails       0.115985\n",
      "13215          mess       0.118060\n",
      "9548       harmless       0.118065\n"
     ]
    }
   ],
   "source": [
    "perword_neg, perword_pos = zip(*perword_proba)\n",
    "# make dict with negative and  positive probs plus actual word\n",
    "perword_dict = {'word':features, 'prob negative':perword_neg, 'prob positive':perword_pos}\n",
    "# convert to df for easier processing\n",
    "perword_df = pd.DataFrame(data = perword_dict)\n",
    "\n",
    "# sort each in descending order, grab top 10, print\n",
    "print 'Top 10 positive Predictor Words according to Logistic Regression classifier: \\n', perword_df.sort(columns='prob positive', ascending=False).iloc[1:10,[2,0]],'\\n'\n",
    "\n",
    "print 'Top 10 negative Predictor Words according to Logistic Regression classifier: \\n', perword_df.sort(columns='prob negative', ascending=False).iloc[1:10,[2,1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_test represents 7870 documents with 24221 features\n",
      "y_test has 3027 positive and 4843 negative labels\n",
      "first testing file is data-LR\\test\\pos\\18001.txt\n",
      "last testing file is data-LR\\test\\neg\\22843.txt\n",
      "testing accuracy=0.7227\n"
     ]
    }
   ],
   "source": [
    "#calculate testing accuracy again by generating vocabulary on reviews present in the test folder. \n",
    "#Here we again use the Logistic regression classifier at first to predict the accuracy on test data.\n",
    "pos_test_files = get_files(path + os.sep + 'test' + os.sep + 'pos')\n",
    "neg_test_files = get_files(path + os.sep + 'test' + os.sep + 'neg')\n",
    "all_test_files = pos_test_files + neg_test_files\n",
    "# Note that we call .transform, not .fit_transform, since we \n",
    "# don't want to learn a new vocabulary.\n",
    "X_test = vec.transform(all_test_files)\n",
    "y_test = np.array([1] * len(pos_test_files) + [0] * len(neg_test_files))\n",
    "print('X_test represents %d documents with %d features' % (X_test.shape[0], X_test.shape[1]))\n",
    "print('y_test has %d positive and %d negative labels' % (len(np.where(y_test==1)[0]),\n",
    "                                                          len(np.where(y_test==0)[0])))\n",
    "print('first testing file is %s' % all_test_files[0])\n",
    "print('last testing file is %s' % all_test_files[-1])\n",
    "print('testing accuracy=%.4g' % accuracy_score(y_test, clf.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testing accuracy=0.72503\n"
     ]
    }
   ],
   "source": [
    "def train_after_removing_features(X, y, vec, features_to_remove):\n",
    "    \"\"\"\n",
    "    Set to 0 the columns of X corresponding to the terms in features_to_remove. \n",
    "    Then, train a new classifier on X and y and return the result.\n",
    "    Params:\n",
    "        X....................the training matrix\n",
    "        y....................the true labels for each row in X\n",
    "        features_to_remove...a list of strings (entries in the vocabulary) that\n",
    "                             should be removed from X\n",
    "    Returns:\n",
    "       The classifier fit on the modified X data.\n",
    "    \"\"\"\n",
    "    arr=X.toarray()\n",
    "    shape = X.get_shape()\n",
    "    for each in features_to_remove:\n",
    "        r=0\n",
    "        res=index_of_term(vec,each)\n",
    "        while r<shape[0]:\n",
    "            arr[r][res] = 0\n",
    "            r=r+1\n",
    "    clf = get_clf()\n",
    "    clf.fit(arr, y)\n",
    "    return clf\n",
    "    \n",
    "    \n",
    "clf = train_after_removing_features(X.copy(), y, vec, ['film'])\n",
    "print('testing accuracy=%.5g' % accuracy_score(y_test, clf.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'filename': 'data-LR\\\\test\\\\pos\\\\20994.txt',\n",
       "  'index': 2993,\n",
       "  'predicted': 0,\n",
       "  'probas': array([ 0.99890797,  0.00109203]),\n",
       "  'truth': 1},\n",
       " {'filename': 'data-LR\\\\test\\\\neg\\\\22197.txt',\n",
       "  'index': 7223,\n",
       "  'predicted': 1,\n",
       "  'probas': array([ 0.00124462,  0.99875538]),\n",
       "  'truth': 0},\n",
       " {'filename': 'data-LR\\\\test\\\\pos\\\\20379.txt',\n",
       "  'index': 2378,\n",
       "  'predicted': 0,\n",
       "  'probas': array([ 0.99869523,  0.00130477]),\n",
       "  'truth': 1},\n",
       " {'filename': 'data-LR\\\\test\\\\neg\\\\21555.txt',\n",
       "  'index': 6581,\n",
       "  'predicted': 1,\n",
       "  'probas': array([ 0.0016089,  0.9983911]),\n",
       "  'truth': 0},\n",
       " {'filename': 'data-LR\\\\test\\\\pos\\\\18440.txt',\n",
       "  'index': 439,\n",
       "  'predicted': 0,\n",
       "  'probas': array([ 0.99726171,  0.00273829]),\n",
       "  'truth': 1},\n",
       " {'filename': 'data-LR\\\\test\\\\pos\\\\20006.txt',\n",
       "  'index': 2005,\n",
       "  'predicted': 0,\n",
       "  'probas': array([ 0.99685599,  0.00314401]),\n",
       "  'truth': 1},\n",
       " {'filename': 'data-LR\\\\test\\\\pos\\\\19188.txt',\n",
       "  'index': 1187,\n",
       "  'predicted': 0,\n",
       "  'probas': array([ 0.99602176,  0.00397824]),\n",
       "  'truth': 1},\n",
       " {'filename': 'data-LR\\\\test\\\\pos\\\\19587.txt',\n",
       "  'index': 1586,\n",
       "  'predicted': 0,\n",
       "  'probas': array([ 0.99571259,  0.00428741]),\n",
       "  'truth': 1},\n",
       " {'filename': 'data-LR\\\\test\\\\pos\\\\18449.txt',\n",
       "  'index': 448,\n",
       "  'predicted': 0,\n",
       "  'probas': array([ 0.99556498,  0.00443502]),\n",
       "  'truth': 1},\n",
       " {'filename': 'data-LR\\\\test\\\\pos\\\\19438.txt',\n",
       "  'index': 1437,\n",
       "  'predicted': 0,\n",
       "  'probas': array([ 0.99472184,  0.00527816]),\n",
       "  'truth': 1}]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_top_errors(X_test, y_test, filenames, clf, n=10):\n",
    "    \"\"\"\n",
    "    Use clf to predict the labels of the testing data in X_test. \n",
    "    We want to find incorrectly predicted documents. Furthermore, we want to look at those \n",
    "    where the probability of the incorrect label, according to the classifier, is highest.\n",
    "    Use the .predict_proba method of the classifier to get the probabilities of\n",
    "    each class label. Return the n documents that were misclassified, sorted by the\n",
    "    probability of the incorrect label. The returned value is a list of dicts, defined below.\n",
    "    Params:\n",
    "        X_test......the testing matrix\n",
    "        y_test......the true labels for each testing document\n",
    "        filenames...the filenames for each testing document\n",
    "        clf.........a trained LogisticRegression object\n",
    "        n...........the number of errors to return\n",
    "    Returns:\n",
    "        A list of n dicts containing the following key/value pairs:\n",
    "           index: the index of this document (in the filenames array)\n",
    "           probas: a numpy array containing the probability of class 0 and 1\n",
    "           truth: the true label\n",
    "           predicted: the predicted label\n",
    "           filename: the path to the file for this document\n",
    "    \"\"\"\n",
    "    \n",
    "    predict = clf.predict(X_test)\n",
    "    predict_prob = clf.predict_proba(X_test)\n",
    "    res=[]\n",
    "\n",
    "    for i in range(len(predict)):\n",
    "        if predict[i] != y_test[i]:\n",
    "            res.append(({'filename':filenames[i],'index':filenames.index(filenames[i]),'predicted':predict[i],\n",
    "                         'probas':predict_prob[i],'truth':y_test[i]}))\n",
    " \n",
    "    return sorted(res,key=lambda x:abs(max(x['probas'])),reverse=True)[:n]\n",
    " \n",
    "errors = get_top_errors(X_test, y_test, all_test_files, clf)\n",
    "errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for document data-LR\\test\\pos\\18001.txt, the term most predictive of class 0 is treacly (index=22105)\n",
      "for document data-LR\\test\\pos\\18001.txt, the term most predictive of class 1 is irresistibly (index=11111)\n"
     ]
    }
   ],
   "source": [
    "# Given a document, find the term in it that is most strongly associated\n",
    "# with a given class label, according to a trained classifier.\n",
    "def most_predictive_term_in_doc(instance, clf, class_idx):\n",
    "    \"\"\"\n",
    "    Params:\n",
    "        instance....one row in the X csr_matrix, corresponding to a document.\n",
    "        clf.........a trained LogisticRegression classifier\n",
    "        class_idx...0 or 1. The class for which we should find the most \n",
    "                    predictive term in this document.\n",
    "    Returns:\n",
    "        The index corresponding to the term that appears in this instance\n",
    "        and has the highest coefficient for class class_idx.\n",
    "    \"\"\"\n",
    "    x=instance.toarray()\n",
    "    li=np.array(x).tolist()\n",
    "    tup=[]\n",
    "    for i in li:\n",
    "        for k,v in enumerate(i):\n",
    "            if v == 1:\n",
    "                #word_ind.append(k)\n",
    "                tup.append((k,clf.coef_[0][k]))\n",
    "    if class_idx == 1:\n",
    "        res=sorted(tup,key=lambda x: x[1],reverse=True)[0]\n",
    "    elif class_idx == 0:\n",
    "        res=sorted(tup,key=lambda x:x[1])[0]\n",
    "    \n",
    "    return int(res[0])\n",
    "                  \n",
    "neg_idx = most_predictive_term_in_doc(X_test[0], clf, 0)\n",
    "pos_idx = most_predictive_term_in_doc(X_test[0], clf, 1)\n",
    "print('for document %s, the term most predictive of class 0 is %s (index=%d)' %\n",
    "      (all_test_files[0], vec.get_feature_names()[neg_idx], neg_idx))\n",
    "print('for document %s, the term most predictive of class 1 is %s (index=%d)' %\n",
    "      (all_test_files[0], vec.get_feature_names()[pos_idx], pos_idx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"love\" context with window 3: ['drama about doomed love . the film']\n",
      "\"touch\" context with window 5: ['film with a deft comedic touch and a trio of charming']\n"
     ]
    }
   ],
   "source": [
    "def find_contexts(filename, term, window=5):\n",
    "    \"\"\"\n",
    "    Find all context windows in which this term appears in this file.\n",
    "    You should use tokenize_with_not to tokenize this file. \n",
    "    \n",
    "    Params:\n",
    "        filename....the filename for this document.\n",
    "        term........the term to find\n",
    "        window......return this many tokens to the left and this many tokens to\n",
    "                    the right of every occurrence of term in this document\n",
    "    Returns:\n",
    "        a list of strings. Each string contains the matched context window.\n",
    "    \"\"\"\n",
    "    f = open(filename, 'r+').read()\n",
    "    token = tokenize_with_not(f)\n",
    "    res= []\n",
    "    \n",
    "    k=0\n",
    "    for k,v in enumerate(token):\n",
    "        #if cmp(v,term) == 0:\n",
    "        if v == term:\n",
    "            if k+window < len(token):\n",
    "                res.append((' '.join(token[(k-window):(k+window+1)]))) \n",
    "            elif k+window == len(token):\n",
    "                res.append((' '.join(token[(k-window):])))   \n",
    "            else:\n",
    "                res.append((' '.join(token[(k-window):])))\n",
    "                \n",
    "    y = [unicode(i) for i in res]     \n",
    "    return res\n",
    "\n",
    "# Here are some sample outputs on the first test document:\n",
    "print('\"love\" context with window 3: %s' % find_contexts(all_test_files[0], 'love', 3))\n",
    "print('\"touch\" context with window 5: %s' % find_contexts(all_test_files[12], 'touch', 5))\n",
    "#print('\"best\" context: %s' % find_contexts(all_test_files[50], 'best'))\n",
    "#print('\"a\" contexts: %s' % find_contexts(all_test_files[200], 'a'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
